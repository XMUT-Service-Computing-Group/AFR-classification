{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a48b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df4ff4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/data45260/Traindata.txt\", sep='\\t', names=['ClassNo','Sentence' , 'ClassName'])\n",
    "test_df = pd.read_csv(\"data/data45260/Testdata.txt\", sep='\\t',names=['ClassNo','Sentence' , 'ClassName'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "595246b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ClassNo                                           Sentence ClassName\n",
      "0  20150131  Tony Abbott's gaffe in knighting the Queen's h...   Opinion\n",
      "1  20150131  Has so much trouble ever come from something s...   Opinion\n",
      "2  20150131  Blackabbott's clever plan to fix the budget an...   Opinion\n",
      "3  20150131  Burning Credlin is not going to help solve the...   Opinion\n",
      "4  20150130  Food As more local produce heads offshore and ...   Opinion\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38940 entries, 0 to 38939\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ClassNo    38940 non-null  int64 \n",
      " 1   Sentence   38940 non-null  object\n",
      " 2   ClassName  38940 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 912.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b81855b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Opinion', 'News', 'Companies and Markets'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train_df[\"ClassName\"].unique()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db61280e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassName\n",
       "News                     14073\n",
       "Companies and Markets    12563\n",
       "Opinion                  12304\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"ClassName\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bbd6f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassName\n",
       "Companies and Markets    2105\n",
       "News                     2093\n",
       "Opinion                  1709\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"ClassName\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "072b547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import re\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "from torch.nn import Embedding,Conv1d\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn,optim\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffd1cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300  # 设定需要的embedding长度\n",
    "# word_dict是一个单词于id的映射字典，\n",
    "# <pading>的意思是补0，<unk>代表不认识的单词，其实就是glove词向量中没有的单词都会被认为是<unk>\n",
    "word_dict = {'<pading>':0,\"<unk>\": 1}\n",
    "\n",
    "\n",
    "# 加载对应长度的glove预训练词向量，维度越大的词向量加载越慢，300维的词向量文件有1G\n",
    "\n",
    "glove_df = pd.read_csv(\"data/glove.6B.300d.txt\", sep=\" \", quoting=3, header=None, index_col=0)\n",
    "# 生成对应的字典形式，key为单词，value为词向量\n",
    "glove_dict = {key: val.values for key, val in glove_df.T.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68c7c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenize(text: str):\n",
    "    \"\"\" \n",
    "    这是一个切分单词的函数，这个函数除了简单了分词之外，\n",
    "    还会将word_dict补充完整，生成完整的词表映射\n",
    "    \"\"\"\n",
    "    word_index = []\n",
    "    pat = re.compile(r\"[\\w]+|[.,!?;|]\") \n",
    "    tokens = pat.findall(text.lower())  \n",
    "    for token in tokens:\n",
    "        if token not in word_dict:\n",
    "            word_dict[token] = len(word_dict) if token in glove_dict else word_dict[\"<unk>\"]\n",
    "        word_index.append(word_dict[token])\n",
    "    return word_index\n",
    "# 训练集和测试集分词\n",
    "train_text = train_df[\"Sentence\"].apply(lambda s: word_tokenize(str(s)))\n",
    "test_text = test_df[\"Sentence\"].apply(lambda s: word_tokenize(str(s)))\n",
    "MAX_LENGTH = 1000  # 最大句子长度\n",
    "train_text = train_text.apply(lambda x:(x+[0]*MAX_LENGTH)[:MAX_LENGTH])\n",
    "test_text = test_text.apply(lambda x:(x+[0]*MAX_LENGTH)[:MAX_LENGTH])\n",
    "s2i = {'News':0,'Opinion':1,'Companies and Markets':2}\n",
    "# s2i = {'Accounting':1,'Chanticleer':2,'Companies and Markets':3,'Computers':4,'Domain Prestige':5,'Education':6,'Features':7,'Financial Services':8,'Life & Leisure':9,'Market Wrap':10,\n",
    "#       'Marketing & Media':11,'News':12,'Opinion':13,'Perspective':14,'Property':15,'Review':16,'Saleroom':17,'Smart Investor':18,\n",
    "#       'Stock Tables':19,'Supplement':20,'Weekend Fin':21,'World':0}\n",
    "train_df['ClassName']=train_df['ClassName'].replace(s2i).astype(int)\n",
    "test_df['ClassName']=test_df['ClassName'].replace(s2i).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0469e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预训练的词向量矩阵，这个后面会直接输入embedding层\n",
    "glove_embeddings = np.zeros((len(word_dict), embedding_dim))\n",
    "for k, v in word_dict.items():\n",
    "    if v==0:\n",
    "        glove_embeddings[v] = np.zeros(embedding_dim)\n",
    "    glove_embeddings[v] = glove_dict[k] if k in glove_dict else glove_dict[\"<unk>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8cb3f4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommentDataset(Dataset):\n",
    "    def __init__(self,texts,labels):\n",
    "        self.texts=texts\n",
    "        self.labels=labels\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        \"\"\"\n",
    "        item 为数据索引，迭代取第item条数据\n",
    "        \"\"\"\n",
    "        text=torch.tensor(self.texts[item],dtype=torch.long)\n",
    "        label=torch.tensor(self.labels[item],dtype=torch.long)\n",
    "        return {'text_id':text,'label':label}\n",
    "def create_data_loader(X,y,batch_size):\n",
    "    ds=CommentDataset(\n",
    "        texts = X.values,\n",
    "        labels=y.values\n",
    "    )\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "BATCH_SIZE = 32\n",
    "train_data_loader = create_data_loader(train_text,train_df['ClassName'], BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(test_text,test_df['ClassName'], BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "794cd4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, weight, embedding_dim=300, hidden_size=128, num_layers=2, dropout=0.5):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(weight, freeze=False)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.rnn = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size,\n",
    "                           num_layers=num_layers, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.out = nn.Linear(hidden_size, 3)\n",
    "    def forward(self, X):\n",
    "        X = self.embedding(X)\n",
    "        output, _ = self.rnn(X)\n",
    "        output = torch.cat((output[:, -1, :self.hidden_size], output[:, 0, self.hidden_size:]), dim=1)\n",
    "        output = self.out(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b797e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76d31da",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 设置CUDA\n",
    "N_EPOCHS = 30     # 设置模型训练次数\n",
    "learning_rate = 3e-4  # 初始学习率\n",
    "model_name = 'BiLSTM'\n",
    "model= BiLSTM(torch.from_numpy(glove_embeddings).float())\n",
    "model = model.to(device)\n",
    "# 优化器\n",
    "optimizer = Adam(model.parameters(),learning_rate)\n",
    "\n",
    "# 损失\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "best_acc = 0\n",
    "for epoch in tqdm(range(N_EPOCHS)):\n",
    "    #启用模型的训练模式\n",
    "    model.train()\n",
    "    # 定义损失\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    val_number = 0\n",
    "    for batch in train_data_loader:\n",
    "        text_id = batch['text_id'].to(device)\n",
    "        label = batch['label'].to(device)\n",
    "        predictions = model(text_id)\n",
    "        loss = criterion(predictions, label)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        preds = predictions.max(1)[1]\n",
    "        epoch_acc += ((preds==label).sum().item())\n",
    "        val_number += label.size(0)\n",
    "    history[f'{model_name}_train_loss'].append(epoch_loss / len(train_data_loader))\n",
    "    history[f'{model_name}_train_accuracy'].append(epoch_acc / val_number)\n",
    "    print(f'第{epoch+1}轮，训练Loss：',epoch_loss / len(train_data_loader),'，训练准确率：',epoch_acc / val_number)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "226997f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'ju32BiLStmepoch30learnrate3e-4'\n",
    "torch.save(model.state_dict(), save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "547ec2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 设置CUDA\n",
    "model_name = 'BiLSTM'\n",
    "model= BiLSTM(torch.from_numpy(glove_embeddings).float())\n",
    "model = model.to(device)\n",
    "# 优化器\n",
    "optimizer = Adam(model.parameters(),learning_rate)\n",
    "\n",
    "# 损失\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4a5b9170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_path='pyBiLStmepoch30learnrate3e-4'\n",
    "model.load_state_dict(torch.load(load_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7ce3205d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试Loss： 1.120144334050917 ，测试准确率： 0.744709666497376\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "# 初始化损失\n",
    "epoch_loss = 0\n",
    "epoch_acc = 0\n",
    "val_number = 0\n",
    "predictions_test = []\n",
    "labels_test = []\n",
    "# 不计算梯度\n",
    "with torch.no_grad():\n",
    "    for batch in val_data_loader:\n",
    "        text_id = batch['text_id'].to(device)\n",
    "        label = batch['label'].to(device)\n",
    "        predictions = model(text_id)\n",
    "        loss = criterion(predictions, label)\n",
    "        epoch_loss += loss.item()\n",
    "        preds = predictions.max(1)[1]\n",
    "        epoch_acc += ((preds == label).sum().item())\n",
    "        val_number += label.size(0)\n",
    "        predictions_test.extend(preds.tolist())\n",
    "        labels_test.extend(label.tolist())\n",
    "history[f'{model_name}_test_loss'].append(epoch_loss / len(val_data_loader))\n",
    "history[f'{model_name}_test_accuracy'].append(epoch_acc / val_number)\n",
    "if best_acc < (epoch_acc / val_number):\n",
    "    best_acc = epoch_acc / val_number\n",
    "print('测试Loss：', epoch_loss / len(val_data_loader), '，测试准确率：', epoch_acc / val_number)\n",
    "print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c68c9342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV文件写入完成\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "filename = '33trainLoss.csv'\n",
    "\n",
    "# 使用 'w' 模式打开文件\n",
    "with open(filename, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # 写入每一个预测值\n",
    "    for prediction in history['BiLSTM_train_loss'][50:]:\n",
    "        writer.writerow([prediction])\n",
    "\n",
    "print('CSV文件写入完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fda0a9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV文件写入完成\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "filename = '33trainacc.csv'\n",
    "\n",
    "# 使用 'w' 模式打开文件\n",
    "with open(filename, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # 写入每一个预测值\n",
    "    for prediction in history['BiLSTM_train_accuracy'][50:]:\n",
    "        writer.writerow([prediction])\n",
    "\n",
    "print('CSV文件写入完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c408c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "# 初始化损失\n",
    "epoch_loss = 0\n",
    "epoch_acc = 0\n",
    "val_number = 0\n",
    "predictions_test = []\n",
    "labels_test = []\n",
    "# 不计算梯度\n",
    "with torch.no_grad():\n",
    "    for batch in val_data_loader:\n",
    "        text_id = batch['text_id'].to(device)\n",
    "        label = batch['label'].to(device)\n",
    "        predictions = model(text_id)\n",
    "        loss = criterion(predictions, label)\n",
    "        epoch_loss += loss.item()\n",
    "        preds = predictions.max(1)[1]\n",
    "        epoch_acc += ((preds == label).sum().item())\n",
    "        val_number += label.size(0)\n",
    "        predictions_test.extend(preds.tolist())\n",
    "        labels_test.extend(label.tolist())\n",
    "history[f'{model_name}_test_loss'].append(epoch_loss / len(val_data_loader))\n",
    "history[f'{model_name}_test_accuracy'].append(epoch_acc / val_number)\n",
    "if best_acc < (epoch_acc / val_number):\n",
    "    best_acc = epoch_acc / val_number\n",
    "print('测试Loss：', epoch_loss / len(val_data_loader), '，测试准确率：', epoch_acc / val_number)\n",
    "print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8553ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(16,5),dpi=150)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history['BiLSTM_train_loss'],label='BiLSTM')\n",
    "# plt.plot(history['CNNText_inception_test_loss'],label='CNNText_inception')\n",
    "plt.title('Train Loss')\n",
    "\n",
    "# 设置坐标轴刻度\n",
    "plt.xticks(range(1,31))\n",
    "plt.gca().xaxis.set_major_locator(ticker.MultipleLocator(4)) # 横坐标间隔为4\n",
    "\n",
    "# 添加图例并设置位置\n",
    "# plt.legend(frameon=True, loc='upper right', facecolor='white', bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history['BiLSTM_train_accuracy'],label='BiLSTM')\n",
    "# plt.plot(history['CNNText_inception_test_accuracy'],label='CNNText_inception')\n",
    "plt.title('Train Accuracy')\n",
    "plt.legend(frameon=True,loc='lower right',facecolor='white')\n",
    "plt.xticks(range(1,31))\n",
    "plt.gca().xaxis.set_major_locator(ticker.MultipleLocator(4)) # 横坐标间隔为5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle-demo",
   "language": "python",
   "name": "paddle-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
