{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84e886c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0a72986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "    ClassNo                                           Sentence ClassName\n",
      "0  20150131  Tony Abbott's gaffe in knighting the Queen's h...   Opinion\n",
      "1  20150131  Has so much trouble ever come from something s...   Opinion\n",
      "2  20150131  Blackabbott's clever plan to fix the budget an...   Opinion\n",
      "3  20150131  Burning Credlin is not going to help solve the...   Opinion\n",
      "4  20150130  Food As more local produce heads offshore and ...   Opinion\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38940 entries, 0 to 38939\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ClassNo    38940 non-null  int64 \n",
      " 1   Sentence   38940 non-null  object\n",
      " 2   ClassName  38940 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 912.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"data/data45260/Traindata.txt\", sep='\\t', names=['ClassNo','Sentence' , 'ClassName'])\n",
    "print(\"Train Set\")\n",
    "print(train_df.head())\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5391f02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ClassNo                                           Sentence ClassName\n",
      "0  20150131  Tony Abbott's gaffe in knighting the Queen's h...   Opinion\n",
      "1  20150131  Has so much trouble ever come from something s...   Opinion\n",
      "2  20150131  Blackabbott's clever plan to fix the budget an...   Opinion\n",
      "3  20150131  Burning Credlin is not going to help solve the...   Opinion\n",
      "4  20150130  Food As more local produce heads offshore and ...   Opinion\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "934e15c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set\n",
      "    ClassNo                                           Sentence ClassName\n",
      "0  20210130  Global perspective Joe Biden would face the mo...   Opinion\n",
      "1  20210130  Two of the great tidal forces in the modern wo...   Opinion\n",
      "2  20210130  On the other hand Labor's new climate spokesma...   Opinion\n",
      "3  20210130  The nation There's no sense of a cut-through f...   Opinion\n",
      "4  20210129  Relations with Beijing The new administration ...   Opinion\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5907 entries, 0 to 5906\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ClassNo    5907 non-null   int64 \n",
      " 1   Sentence   5907 non-null   object\n",
      " 2   ClassName  5907 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 138.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"data/data45260/Testdata.txt\", sep='\\t',names=['ClassNo','Sentence' , 'ClassName'])\n",
    "print(\"Test Set\")\n",
    "print(test_df.head())\n",
    "\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03eb734d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Opinion', 'News', 'Companies and Markets'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train_df[\"ClassName\"].unique()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a554076e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_classes = len(labels)\n",
    "num_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3b20713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassName\n",
       "News                     14073\n",
       "Companies and Markets    12563\n",
       "Opinion                  12304\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"ClassName\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5f72723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassName\n",
       "News                     14073\n",
       "Companies and Markets    12563\n",
       "Opinion                  12304\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"ClassName\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6e7b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import re\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "from torch.nn import Embedding,Conv1d\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn,optim\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80b7516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300  # 设定需要的embedding长度\n",
    "# word_dict是一个单词于id的映射字典，\n",
    "# <pading>的意思是补0，<unk>代表不认识的单词，其实就是glove词向量中没有的单词都会被认为是<unk>\n",
    "word_dict = {'<pading>':0,\"<unk>\": 1}\n",
    "\n",
    "\n",
    "# 加载对应长度的glove预训练词向量，维度越大的词向量加载越慢，300维的词向量文件有1G\n",
    "\n",
    "glove_df = pd.read_csv(\"data/glove.6B.300d.txt\", sep=\" \", quoting=3, header=None, index_col=0)\n",
    "# 生成对应的字典形式，key为单词，value为词向量\n",
    "glove_dict = {key: val.values for key, val in glove_df.T.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27594fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenize(text: str):\n",
    "    \"\"\" \n",
    "    这是一个切分单词的函数，这个函数除了简单了分词之外，\n",
    "    还会将word_dict补充完整，生成完整的词表映射\n",
    "    \"\"\"\n",
    "    word_index = []\n",
    "    pat = re.compile(r\"[\\w]+|[.,!?;|]\") \n",
    "    tokens = pat.findall(text.lower())  \n",
    "    for token in tokens:\n",
    "        if token not in word_dict:\n",
    "            word_dict[token] = len(word_dict) if token in glove_dict else word_dict[\"<unk>\"]\n",
    "        word_index.append(word_dict[token])\n",
    "    return word_index\n",
    "# 训练集和测试集分词\n",
    "train_text = train_df[\"Sentence\"].apply(lambda s: word_tokenize(str(s)))\n",
    "test_text = test_df[\"Sentence\"].apply(lambda s: word_tokenize(str(s)))\n",
    "MAX_LENGTH = 1000  # 最大句子长度\n",
    "train_text = train_text.apply(lambda x:(x+[0]*MAX_LENGTH)[:MAX_LENGTH])\n",
    "test_text = test_text.apply(lambda x:(x+[0]*MAX_LENGTH)[:MAX_LENGTH])\n",
    "s2i = {'News':0,'Opinion':1,'Companies and Markets':2}\n",
    "# s2i = {'Accounting':1,'Chanticleer':2,'Companies and Markets':3,'Computers':4,'Domain Prestige':5,'Education':6,'Features':7,'Financial Services':8,'Life & Leisure':9,'Market Wrap':10,\n",
    "#       'Marketing & Media':11,'News':12,'Opinion':13,'Perspective':14,'Property':15,'Review':16,'Saleroom':17,'Smart Investor':18,\n",
    "#       'Stock Tables':19,'Supplement':20,'Weekend Fin':21,'World':0}\n",
    "train_df['ClassName']=train_df['ClassName'].replace(s2i).astype(int)\n",
    "test_df['ClassName']=test_df['ClassName'].replace(s2i).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f6c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预训练的词向量矩阵，这个后面会直接输入embedding层\n",
    "glove_embeddings = np.zeros((len(word_dict), embedding_dim))\n",
    "for k, v in word_dict.items():\n",
    "    if v==0:\n",
    "        glove_embeddings[v] = np.zeros(embedding_dim)\n",
    "    glove_embeddings[v] = glove_dict[k] if k in glove_dict else glove_dict[\"<unk>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aa695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommentDataset(Dataset):\n",
    "    def __init__(self,texts,labels):\n",
    "        self.texts=texts\n",
    "        self.labels=labels\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        \"\"\"\n",
    "        item 为数据索引，迭代取第item条数据\n",
    "        \"\"\"\n",
    "        text=torch.tensor(self.texts[item],dtype=torch.long)\n",
    "        label=torch.tensor(self.labels[item],dtype=torch.long)\n",
    "        return {'text_id':text,'label':label}\n",
    "def create_data_loader(X,y,batch_size):\n",
    "    ds=CommentDataset(\n",
    "        texts = X.values,\n",
    "        labels=y.values\n",
    "    )\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "BATCH_SIZE = 128\n",
    "train_data_loader = create_data_loader(train_text,train_df['ClassName'], BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(test_text,test_df['ClassName'], BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b92d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module): \n",
    "    def __init__(self,weight, embedding_dim=300,dropout=0.4):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(weight,freeze=False)  # 仍然训练词向量\n",
    "        self.kernel_size = [3,4,5,6]\n",
    "        self.conv = nn.ModuleList([nn.Sequential(\n",
    "                Conv1d(in_channels=embedding_dim, out_channels=1, kernel_size=k, stride=2),\n",
    "                nn.PReLU(),\n",
    "                nn.MaxPool1d(4, stride=2)) for k in self.kernel_size])\n",
    "        self.Linear = nn.Linear(992,3)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    def forward(self, X):\n",
    "        X = self.embedding(X).permute(0,2,1)   \n",
    "        X = [c(X).squeeze() for c in self.conv]  \n",
    "        X = torch.cat(X,dim=1)  \n",
    "        out = self.dropout(self.Linear(X)) \n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b9a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcbc11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "test_f1_scores = []\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 设置CUDA\n",
    "N_EPOCHS = 30  # 设置模型训练次数\n",
    "learning_rate = 0.001   # 初始学习率\n",
    "model_name = 'TextCNN'\n",
    "model = TextCNN(torch.from_numpy(glove_embeddings).float())\n",
    "model = model.to(device)\n",
    "# 优化器\n",
    "optimizer = Adam(model.parameters(), learning_rate)\n",
    "\n",
    "# 损失\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "best_acc = 0\n",
    "\n",
    "# 在训练循环之前添加计时代码\n",
    "train_start_time = time.time()\n",
    "for epoch in tqdm(range(N_EPOCHS)):\n",
    "    # 启用模型的训练模式\n",
    "    model.train()\n",
    "    # 定义损失\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    val_number = 0\n",
    "    for batch in train_data_loader:\n",
    "        text_id = batch['text_id'].to(device)\n",
    "        label = batch['label'].to(device)\n",
    "        predictions = model(text_id)\n",
    "        loss = criterion(predictions, label)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        preds = predictions.max(1)[1]\n",
    "        epoch_acc += ((preds == label).sum().item())\n",
    "        val_number += label.size(0)\n",
    "    history[f'{model_name}_train_loss'].append(epoch_loss / len(train_data_loader))\n",
    "    history[f'{model_name}_train_accuracy'].append(epoch_acc / val_number)\n",
    "    print(f'第{epoch + 1}轮，训练Loss：', epoch_loss / len(train_data_loader), '，训练准确率：', epoch_acc / val_number)\n",
    "train_end_time = time.time()\n",
    "train_total_time = train_end_time - train_start_time\n",
    "print(\"训练总运行时间: \", train_total_time, \"秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bedd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "# 初始化损失\n",
    "epoch_loss = 0\n",
    "epoch_acc = 0\n",
    "val_number = 0\n",
    "predictions_test = []\n",
    "labels_test = []\n",
    "# 不计算梯度\n",
    "with torch.no_grad():\n",
    "    for batch in val_data_loader:\n",
    "        text_id = batch['text_id'].to(device)\n",
    "        label = batch['label'].to(device)\n",
    "        predictions = model(text_id)\n",
    "        loss = criterion(predictions, label)\n",
    "        epoch_loss += loss.item()\n",
    "        preds = predictions.max(1)[1]\n",
    "        epoch_acc += ((preds == label).sum().item())\n",
    "        val_number += label.size(0)\n",
    "        predictions_test.extend(preds.tolist())\n",
    "        labels_test.extend(label.tolist())\n",
    "history[f'{model_name}_test_loss'].append(epoch_loss / len(val_data_loader))\n",
    "history[f'{model_name}_test_accuracy'].append(epoch_acc / val_number)\n",
    "if best_acc < (epoch_acc / val_number):\n",
    "    best_acc = epoch_acc / val_number\n",
    "print('测试Loss：', epoch_loss / len(val_data_loader), '，测试准确率：', epoch_acc / val_number)\n",
    "print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004b8a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "filename = 'label.csv'\n",
    "\n",
    "# 使用 'w' 模式打开文件\n",
    "with open(filename, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # 写入每一个预测值\n",
    "    for prediction in labels_test:\n",
    "        writer.writerow([prediction])\n",
    "\n",
    "print('CSV文件写入完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dee411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "filename = 'predictions.csv'\n",
    "\n",
    "# 使用 'w' 模式打开文件\n",
    "with open(filename, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # 写入每一个预测值\n",
    "    for prediction in predictions_test:\n",
    "        writer.writerow([prediction])\n",
    "\n",
    "print('CSV文件写入完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b19e548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(16,5),dpi=150)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history['TextCNN_train_loss'],label='TextCNN')\n",
    "# plt.plot(history['CNNText_inception_test_loss'],label='CNNText_inception')\n",
    "plt.title('Train Loss')\n",
    "\n",
    "# 设置坐标轴刻度\n",
    "plt.xticks(range(1,51))\n",
    "plt.gca().xaxis.set_major_locator(ticker.MultipleLocator(4)) # 横坐标间隔为4\n",
    "\n",
    "# 添加图例并设置位置\n",
    "plt.legend(frameon=True, loc='upper right', facecolor='white', bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history['TextCNN_train_accuracy'],label='TextCNN')\n",
    "# plt.plot(history['CNNText_inception_test_accuracy'],label='CNNText_inception')\n",
    "plt.title('Train Accuracy')\n",
    "plt.legend(frameon=True,loc='lower right',facecolor='white')\n",
    "plt.xticks(range(1,51))\n",
    "plt.gca().xaxis.set_major_locator(ticker.MultipleLocator(4)) # 横坐标间隔为5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432c25e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# 假设y_true和y_pred分别是真实标签和预测标签\n",
    "y_true = labels_test\n",
    "y_pred = predictions_test\n",
    "\n",
    "# 计算精确度、召回率和F1分数\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "\n",
    "print(\"Macro Precision:\", precision)\n",
    "print(\"Macro Recall:\", recall)\n",
    "print(\"Macro F1 Score:\", f1)\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(\"Weighted Precision:\", precision)\n",
    "print(\"Weighted Recall:\", recall)\n",
    "print(\"Weighted F1 Score:\", f1)\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "\n",
    "print(\"Micro Precision:\", precision)\n",
    "print(\"Micro Recall:\", recall)\n",
    "print(\"Micro F1 Score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle-demo",
   "language": "python",
   "name": "paddle-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
